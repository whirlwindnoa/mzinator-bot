{
    "discord_token": "",
    "inference_token": "",

    "parameters": {
        "temperature": 1,
        "max_tokens": 64,
        "model": "text-davinci-003",
        "context": ""
    }
}
